{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22820,
     "status": "ok",
     "timestamp": 1684092982953,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "d2vE9zgT7A5q",
    "outputId": "de3493e6-2882-4ed0-bf63-2ea8d9f34a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: shortuuid in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-contrib-python\n",
    "!pip install imutils\n",
    "#!pip install scikit-learn\n",
    "#!pip install tqdm\n",
    "!pip install shortuuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6590,
     "status": "ok",
     "timestamp": 1687112336204,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "wOXbdDNs53Eh",
    "outputId": "e292f3ed-64f6-4cdb-b265-4e37e97c961f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from os.path import exists\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_coords(path):\n",
    "\t\tpath_no_ext = os.path.splitext(path)[0]\n",
    "\t\tcoords = os.path.basename(path_no_ext).split('_')[-2:]\n",
    "\t\treturn tuple([int(x) for x in coords])\n",
    "\n",
    "\n",
    "def filter_data_present_in_other_set(Imgs, masks, slices_to_filter_out):\n",
    "\t\tslices_to_filter_out = set([slice_coords(path) for path in slices_to_filter_out])\n",
    "\t\tfor k in Imgs:\n",
    "\t\t\t\tpaths_to_keep = [path for path in Imgs[k] if slice_coords(path) not in slices_to_filter_out]\n",
    "\t\t\t\tImgs[k] = paths_to_keep\n",
    "\n",
    "\t\tpaths_to_keep = [path for path in masks if slice_coords(path) not in slices_to_filter_out]\n",
    "\t\tmasks = paths_to_keep\n",
    "\n",
    "\t\treturn Imgs, masks\n",
    "    \n",
    "def splitting_forest_dataset(image0Paths,\n",
    "\t\t\t\t\t\t\timage1Paths,\n",
    "\t\t\t\t\t\t\timage2Paths,\n",
    "\t\t\t\t\t\t\timage3Paths,\n",
    "\t\t\t\t\t\t\timage4Paths,\n",
    "\t\t\t\t\t\t\timage5Paths,\n",
    "\t\t\t\t\t\t\timage6Paths,\n",
    "\t\t\t\t\t\t\timage7Paths,\n",
    "\t\t\t\t\t\t\tmaskPaths,\n",
    "\t\t\t\t\t\t\tTEST_SPLIT,\n",
    "\t\t\t\t\t\t\tRANDOM_STATE):\n",
    "\n",
    "\t\tsplit = train_test_split(image0Paths,\n",
    "\t\t\t\t\t\t\timage1Paths,\n",
    "\t\t\t\t\t\t\timage2Paths,\n",
    "\t\t\t\t\t\t\timage3Paths,\n",
    "\t\t\t\t\t\t\timage4Paths,\n",
    "\t\t\t\t\t\t\timage5Paths,\n",
    "\t\t\t\t\t\t\timage6Paths,\n",
    "\t\t\t\t\t\t\timage7Paths,\n",
    "\t\t\t\t\t\t\tmaskPaths,\n",
    "\t\t\t\t\t\t\ttest_size=TEST_SPLIT,\n",
    "\t\t\t\t\t\t\trandom_state=RANDOM_STATE)\n",
    "\n",
    "\t\t(trainImages0, testImages0) = split[:2]\n",
    "\t\t(trainImages1, testImages1) = split[2:4]\n",
    "\t\t(trainImages2, testImages2) = split[4:6]\n",
    "\t\t(trainImages3, testImages3) = split[6:8]\n",
    "\t\t(trainImages4, testImages4) = split[8:10]\n",
    "\t\t(trainImages5, testImages5) = split[10:12]\n",
    "\t\t(trainImages6, testImages6) = split[12:14]\n",
    "\t\t(trainImages7, testImages7) = split[14:16]\n",
    "\t\t(trainMasks, testMasks) = split[16:]\n",
    "\n",
    "\t\ttrainImages = {\n",
    "\t\t\t\t0: trainImages0,\n",
    "\t\t\t\t1: trainImages1,\n",
    "\t\t\t\t2: trainImages2,\n",
    "\t\t\t\t3: trainImages3,\n",
    "\t\t\t\t4: trainImages4,\n",
    "\t\t\t\t5: trainImages5,\n",
    "\t\t\t\t6: trainImages6,\n",
    "\t\t\t\t7: trainImages7,\n",
    "\t\t}\n",
    "\n",
    "\t\ttestImages = {\n",
    "\t\t\t\t0: testImages0,\n",
    "\t\t\t\t1: testImages1,\n",
    "\t\t\t\t2: testImages2,\n",
    "\t\t\t\t3: testImages3,\n",
    "\t\t\t\t4: testImages4,\n",
    "\t\t\t\t5: testImages5,\n",
    "\t\t\t\t6: testImages6,\n",
    "\t\t\t\t7: testImages7,\n",
    "\t\t}\n",
    "\n",
    "\t\treturn trainImages, testImages, trainMasks, testMasks\n",
    "\n",
    "## NEW WAY\n",
    "def load_img_and_mask_paths(mask_version='nks', single_set=True, TEST_SPLIT=None, RANDOM_STATE=None): # TEST_SPLIT is proportional size of test set retunred\n",
    "\t\twv2_0_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_0-{mask_version}.csv')\n",
    "\t\twv2_1_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_1-{mask_version}.csv')\n",
    "\t\twv2_2_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_2-{mask_version}.csv')\n",
    "\t\twv2_3_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_3-{mask_version}.csv')\n",
    "\t\twv2_4_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_4-{mask_version}.csv')\n",
    "\t\twv2_5_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_5-{mask_version}.csv')\n",
    "\t\twv2_6_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_6-{mask_version}.csv')\n",
    "\t\twv2_7_data = pd.read_csv(f'/data/ForestDataset8C/Dataset-wv2_7-{mask_version}.csv')\n",
    "\t\timage0Paths = list(sorted(wv2_0_data.imgPath))\n",
    "\t\timage1Paths = list(sorted(wv2_1_data.imgPath))\n",
    "\t\timage2Paths = list(sorted(wv2_2_data.imgPath))\n",
    "\t\timage3Paths = list(sorted(wv2_3_data.imgPath))\n",
    "\t\timage4Paths = list(sorted(wv2_4_data.imgPath))\n",
    "\t\timage5Paths = list(sorted(wv2_5_data.imgPath))\n",
    "\t\timage6Paths = list(sorted(wv2_6_data.imgPath))\n",
    "\t\timage7Paths = list(sorted(wv2_7_data.imgPath))\n",
    "\t\tmaskPaths = list(sorted(wv2_7_data.maskPath))\n",
    "\n",
    "\t\tl = [image0Paths,\n",
    "             image1Paths,\n",
    "             image2Paths,\n",
    "             image3Paths,\n",
    "             image4Paths,\n",
    "             image5Paths,\n",
    "             image6Paths,\n",
    "             image7Paths,\n",
    "             maskPaths]\n",
    "\t\tfor dataset in l:\n",
    "\t\t\t\tassert len(l[0]) == len(dataset), \"List of paths of diffrenet length for differen channels/mask\"\n",
    "\t\tfor i in range(len(image0Paths)):\n",
    "\t\t\t\tassert all([slice_coords(image0Paths[i]) == slice_coords(img_dataset[i]) for img_dataset in l]), \"Slices out of order for different channels/mask of dataset\"\n",
    "                \n",
    "\t\tif single_set:\n",
    "\t\t\t\tImgs = {\n",
    "\t\t\t\t\t\t0: image0Paths,\n",
    "\t\t\t\t\t\t1: image1Paths,\n",
    "\t\t\t\t\t\t2: image2Paths,\n",
    "\t\t\t\t\t\t3: image3Paths,\n",
    "\t\t\t\t\t\t4: image4Paths,\n",
    "\t\t\t\t\t\t5: image5Paths,\n",
    "\t\t\t\t\t\t6: image6Paths,\n",
    "\t\t\t\t\t\t7: image7Paths,\n",
    "\t\t\t\t}\n",
    "\t\t\t\treturn Imgs, maskPaths\n",
    "\t\treturn splitting_forest_dataset(image0Paths,\n",
    "\t\t\t\t\t\t\timage1Paths,\n",
    "\t\t\t\t\t\t\timage2Paths,\n",
    "\t\t\t\t\t\t\timage3Paths,\n",
    "\t\t\t\t\t\t\timage4Paths,\n",
    "\t\t\t\t\t\t\timage5Paths,\n",
    "\t\t\t\t\t\t\timage6Paths,\n",
    "\t\t\t\t\t\t\timage7Paths,\n",
    "\t\t\t\t\t\t\tmaskPaths,\n",
    "\t\t\t\t\t\t\tTEST_SPLIT,\n",
    "\t\t\t\t\t\t\tRANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_counts(paths, labels):\n",
    "    counts = {l: 0 for l in labels}\n",
    "    for path in paths:\n",
    "        mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        mask[mask < 0] = 0 # Background class should be zero not -3.4e+38\n",
    "        counts_in_mask = np.unique(mask, return_counts=True)\n",
    "        for i in range(len(counts_in_mask[0])):\n",
    "            counts[counts_in_mask[0][i]] += counts_in_mask[1][i]\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(counts):\n",
    "    df = pd.DataFrame([counts])\n",
    "    return df.div(df.sum(axis=1)*0.01, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imgs, maskPaths = load_img_and_mask_paths(mask_version='train_polygons')\n",
    "\n",
    "counts_global = get_class_counts(paths=maskPaths, labels=range(13))\n",
    "proportions_global = get_proportions(counts_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3496450,\n",
       " 1: 2941809,\n",
       " 2: 2945983,\n",
       " 3: 878024,\n",
       " 4: 4411736,\n",
       " 5: 1106848,\n",
       " 6: 1325334,\n",
       " 7: 7418729,\n",
       " 8: 2462666,\n",
       " 9: 2201673,\n",
       " 10: 978627,\n",
       " 11: 1051232,\n",
       " 12: 408185}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31627296"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of all counts\n",
    "s=0\n",
    "for k in counts_global: s+= counts_global[k]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3496450</td>\n",
       "      <td>2941809</td>\n",
       "      <td>2945983</td>\n",
       "      <td>878024</td>\n",
       "      <td>4411736</td>\n",
       "      <td>1106848</td>\n",
       "      <td>1325334</td>\n",
       "      <td>7418729</td>\n",
       "      <td>2462666</td>\n",
       "      <td>2201673</td>\n",
       "      <td>978627</td>\n",
       "      <td>1051232</td>\n",
       "      <td>408185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2       3        4        5        6        7   \\\n",
       "0  3496450  2941809  2945983  878024  4411736  1106848  1325334  7418729   \n",
       "\n",
       "        8        9       10       11      12  \n",
       "0  2462666  2201673  978627  1051232  408185  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class counts in total train_polygons\n",
    "df = pd.DataFrame([counts_global])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31627296\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.055166</td>\n",
       "      <td>9.301488</td>\n",
       "      <td>9.314685</td>\n",
       "      <td>2.776159</td>\n",
       "      <td>13.949141</td>\n",
       "      <td>3.499661</td>\n",
       "      <td>4.190475</td>\n",
       "      <td>23.456729</td>\n",
       "      <td>7.786521</td>\n",
       "      <td>6.961306</td>\n",
       "      <td>3.094248</td>\n",
       "      <td>3.323812</td>\n",
       "      <td>1.29061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5         6   \\\n",
       "0  11.055166  9.301488  9.314685  2.776159  13.949141  3.499661  4.190475   \n",
       "\n",
       "          7         8         9         10        11       12  \n",
       "0  23.456729  7.786521  6.961306  3.094248  3.323812  1.29061  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent of class in whole train_polygons datase\n",
    "df.div(df.sum(axis=1)*0.01, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check of above\n",
    "df.div(df.sum(axis=1)*0.01, axis=0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.055166</td>\n",
       "      <td>9.301488</td>\n",
       "      <td>9.314685</td>\n",
       "      <td>2.776159</td>\n",
       "      <td>13.949141</td>\n",
       "      <td>3.499661</td>\n",
       "      <td>4.190475</td>\n",
       "      <td>23.456729</td>\n",
       "      <td>7.786521</td>\n",
       "      <td>6.961306</td>\n",
       "      <td>3.094248</td>\n",
       "      <td>3.323812</td>\n",
       "      <td>1.29061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5         6   \\\n",
       "0  11.055166  9.301488  9.314685  2.776159  13.949141  3.499661  4.190475   \n",
       "\n",
       "          7         8         9         10        11       12  \n",
       "0  23.456729  7.786521  6.961306  3.094248  3.323812  1.29061  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best split for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:54<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random state was: 74 with sum of diffs: 9.659318752173228 with test_split=0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_rand_state = None\n",
    "sum_of_diffs = []\n",
    "TEST_SPLIT=0.25\n",
    "for rand_state in tqdm.tqdm(range(150)): # same with 400\n",
    "    trainImages, testImages, trainMasks, testMasks = load_img_and_mask_paths(mask_version='train_polygons',\n",
    "                                          single_set=False,\n",
    "                                          TEST_SPLIT=TEST_SPLIT,\n",
    "                                          RANDOM_STATE=rand_state)\n",
    "\n",
    "    counts = get_class_counts(paths=testMasks, labels=range(13))\n",
    "    proportions = get_proportions(counts)\n",
    "    sum_of_diff = np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "    \n",
    "    counts = get_class_counts(paths=trainMasks, labels=range(13))\n",
    "    proportions = get_proportions(counts)\n",
    "    sum_of_diff += np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "    \n",
    "    if best_rand_state is None or sum_of_diff < np.min(sum_of_diffs):\n",
    "        best_rand_state = rand_state\n",
    "    sum_of_diffs.append(sum_of_diff)\n",
    "print(f\"Best Random state was: {best_rand_state} with sum of diffs: {sum_of_diffs[best_rand_state]} with test_split={TEST_SPLIT}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_polygons_dataset(images, masks, name='train_polygons_TRAINING'):\n",
    "    for channel in images:\n",
    "        df = pd.DataFrame({'imgPath': sorted(images[channel]), 'maskPath':sorted(masks)})\n",
    "        df.to_csv(f'/data/ForestDataset8C/Dataset-wv2_{channel}-{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sum of share (%) deviations: 9.659318752173228\n"
     ]
    }
   ],
   "source": [
    "trainImages, testImages, trainMasks, testMasks = load_img_and_mask_paths(mask_version='train_polygons',\n",
    "                                          single_set=False,\n",
    "                                          TEST_SPLIT=0.25,\n",
    "                                          RANDOM_STATE=74)\n",
    "\n",
    "counts = get_class_counts(paths=testMasks, labels=range(13))\n",
    "proportions = get_proportions(counts)\n",
    "sum_of_diff = np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "\n",
    "counts = get_class_counts(paths=trainMasks, labels=range(13))\n",
    "proportions = get_proportions(counts)\n",
    "sum_of_diff += np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "\n",
    "print(f\"total sum of share (%) deviations: {sum_of_diff}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rand_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_polygons_dataset(testImages, testMasks, name='train_polygons_test_0.25_TESTING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fining best split into real traning and validation sets from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [01:46<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random state was: 374 with sum of diffs: 14.837712757149188 with test_split=0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_rand_state = None\n",
    "sum_of_diffs = []\n",
    "TEST_SPLIT=0.25\n",
    "for rand_state in tqdm.tqdm(range(400)): # same with 400\n",
    "    realTrainImages, valImages, realTrainMasks, valMasks = splitting_forest_dataset(trainImages[0],\n",
    "                                                                            trainImages[1],\n",
    "                                                                            trainImages[2],\n",
    "                                                                            trainImages[3],\n",
    "                                                                            trainImages[4],\n",
    "                                                                            trainImages[5],\n",
    "                                                                            trainImages[6],\n",
    "                                                                            trainImages[7],\n",
    "                                                                            trainMasks,\n",
    "                                                                            TEST_SPLIT,\n",
    "                                                                            rand_state)\n",
    "\n",
    "    counts = get_class_counts(paths=valMasks, labels=range(13))\n",
    "    proportions = get_proportions(counts)\n",
    "    sum_of_diff = np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "    \n",
    "    counts = get_class_counts(paths=realTrainMasks, labels=range(13))\n",
    "    proportions = get_proportions(counts)\n",
    "    sum_of_diff += np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "    \n",
    "    if best_rand_state is None or sum_of_diff < np.min(sum_of_diffs):\n",
    "        best_rand_state = rand_state\n",
    "    sum_of_diffs.append(sum_of_diff)\n",
    "print(f\"Best Random state was: {best_rand_state} with sum of diffs: {sum_of_diffs[best_rand_state]} with test_split={TEST_SPLIT}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sum of share (%) deviations: 14.837712757149188\n"
     ]
    }
   ],
   "source": [
    "realTrainImages, valImages, realTrainMasks, valMasks = splitting_forest_dataset(trainImages[0],\n",
    "                                                                            trainImages[1],\n",
    "                                                                            trainImages[2],\n",
    "                                                                            trainImages[3],\n",
    "                                                                            trainImages[4],\n",
    "                                                                            trainImages[5],\n",
    "                                                                            trainImages[6],\n",
    "                                                                            trainImages[7],\n",
    "                                                                            trainMasks,\n",
    "                                                                            TEST_SPLIT,\n",
    "                                                                            374)\n",
    "\n",
    "counts = get_class_counts(paths=valMasks, labels=range(13))\n",
    "proportions = get_proportions(counts)\n",
    "sum_of_diff = np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "    \n",
    "counts = get_class_counts(paths=realTrainMasks, labels=range(13))\n",
    "proportions = get_proportions(counts)\n",
    "sum_of_diff += np.abs((proportions_global - proportions).values.squeeze()[1:]).sum()\n",
    "print(f\"total sum of share (%) deviations: {sum_of_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realTrainMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realTrainImages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valImages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_polygons_dataset(realTrainImages, realTrainMasks, name='train_polygons_test_0.75x0.75_TRAINING')\n",
    "save_train_polygons_dataset(valImages, valMasks, name='train_polygons_test_0.75x0.25_VALIDATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding class weights for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_factor = 0.03\n",
    "raveled_total_trained_set = None\n",
    "for tmask_path in realTrainMasks:\n",
    "    img = cv2.imread(tmask_path, -1) #  cv2.IMREAD_UNCHANGED\n",
    "    img[img < 0] = 0\n",
    "    values, counts = np.unique(img, return_counts=True)\n",
    "    raveled_img = img.ravel()\n",
    "    for v in values:\n",
    "        raveled_img = np.append(raveled_img, [v] * int(np.sum(counts)*smoothing_factor))\n",
    "    if raveled_total_trained_set is None:\n",
    "        raveled_total_trained_set = raveled_img\n",
    "    else:\n",
    "        raveled_total_trained_set = np.append(raveled_total_trained_set, raveled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(raveled_total_trained_set, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68027677 0.86080587 0.7664746  2.73974581 0.55010219 2.27545507\n",
      " 1.52235798 0.35160898 1.08095651 1.10757723 2.21847914 2.06521764\n",
      " 5.6361113 ]\n"
     ]
    }
   ],
   "source": [
    "print(compute_class_weight(class_weight='balanced', classes=values, y=raveled_total_trained_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weight of 0.0 is 0.6802767700064816\n",
      "class weight of 1.0 is 0.860805874461505\n",
      "class weight of 2.0 is 0.766474596412992\n",
      "class weight of 3.0 is 2.739745810690325\n",
      "class weight of 4.0 is 0.5501021875452016\n",
      "class weight of 5.0 is 2.2754550701786496\n",
      "class weight of 6.0 is 1.522357976272553\n",
      "class weight of 7.0 is 0.35160898476724495\n",
      "class weight of 8.0 is 1.080956508247329\n",
      "class weight of 9.0 is 1.1075772287750636\n",
      "class weight of 10.0 is 2.218479136613627\n",
      "class weight of 11.0 is 2.0652176412940286\n",
      "class weight of 12.0 is 5.636111304832973\n"
     ]
    }
   ],
   "source": [
    "class_w = compute_class_weight(class_weight='balanced', classes=values, y=raveled_total_trained_set)\n",
    "for i,v in enumerate(values):\n",
    "    print(f\"class weight of {v} is {class_w[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.85552</td>\n",
       "      <td>8.943498</td>\n",
       "      <td>9.964698</td>\n",
       "      <td>2.871725</td>\n",
       "      <td>13.738203</td>\n",
       "      <td>3.048388</td>\n",
       "      <td>4.523609</td>\n",
       "      <td>22.839647</td>\n",
       "      <td>7.516118</td>\n",
       "      <td>6.869683</td>\n",
       "      <td>3.039827</td>\n",
       "      <td>4.010376</td>\n",
       "      <td>0.778709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3          4         5         6   \\\n",
       "0  11.85552  8.943498  9.964698  2.871725  13.738203  3.048388  4.523609   \n",
       "\n",
       "          7         8         9         10        11        12  \n",
       "0  22.839647  7.516118  6.869683  3.039827  4.010376  0.778709  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = get_class_counts(paths=realTrainMasks, labels=range(13))\n",
    "get_proportions(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOrNFUNxo+sXxfgZPJMtLFh",
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
