{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684091123773,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "bkjuV7h3VnJe"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22397,
     "status": "ok",
     "timestamp": 1684091146164,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "ev-WP3SbMf_o",
    "outputId": "fb96eba2-7a25-4593-9688-6dd6b601e1fd"
   },
   "outputs": [],
   "source": [
    "dir_prefix = '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684091146165,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "wOXbdDNs53Eh"
   },
   "outputs": [],
   "source": [
    "def tile_image(image, \n",
    "               mask, \n",
    "               vertical_splits,\n",
    "               horizontal_splits, \n",
    "               img_tiling_prefix, \n",
    "               mask_tiling_prefix, \n",
    "               target_imgtile_path, \n",
    "               target_masktile_path,\n",
    "               target_csv_dataset_path, \n",
    "               to_exclude_condition, \n",
    "               imgtype='.tif',\n",
    "               skip_img=False,\n",
    "               skip_mask=False\n",
    "               ):\n",
    "    Path(target_imgtile_path).mkdir(exist_ok=True)\n",
    "    Path(target_masktile_path).mkdir(exist_ok=True)\n",
    "    \n",
    "    im = image\n",
    "    imgheight=im.shape[0]\n",
    "    imgwidth=im.shape[1]\n",
    "\n",
    "    assert imgheight == mask.shape[0],'imgheight == mask.shape[0] failed'\n",
    "    assert imgwidth == mask.shape[1],'imgwidth == mask.shape[1] failed'\n",
    "\n",
    "    M = imgheight//horizontal_splits\n",
    "    N = imgwidth//vertical_splits\n",
    "\n",
    "    excluded_regions_num = 0\n",
    "    usable_tiles_dataset = [] #. To be filled with tuples of (path to img tile, path to mask tile) for tiles that are not excluded by the exclude condition\n",
    "\n",
    "    for j in range(horizontal_splits):\n",
    "        for i in range(vertical_splits):  \n",
    "            y = j*M\n",
    "            x = i*N\n",
    "\n",
    "            y1 = y + M\n",
    "            x1 = x + N\n",
    "\n",
    "            if j == (horizontal_splits - 1): y1 = imgheight\n",
    "            if i == (vertical_splits - 1): x1 = imgwidth\n",
    "\n",
    "            tiles_im = im[y:y1,x:x1]\n",
    "            tiles_ma = mask[y:y1,x:x1]\n",
    "\n",
    "            img_tile_filename = target_imgtile_path + '/' + img_tiling_prefix + str(j) + '_' + str(i)+imgtype\n",
    "            mask_tile_filename = target_masktile_path + '/' + mask_tiling_prefix + str(j) + '_' + str(i)+imgtype\n",
    "            if (not skip_img) and (not exists(img_tile_filename)): cv2.imwrite(img_tile_filename,tiles_im)\n",
    "            if (not skip_mask) and (not exists(mask_tile_filename)): cv2.imwrite(mask_tile_filename,tiles_ma)\n",
    "            if not to_exclude_condition(tiles_im, tiles_ma):\n",
    "                usable_tiles_dataset.append((img_tile_filename, mask_tile_filename))\n",
    "            else:\n",
    "                excluded_regions_num += 1\n",
    "    usable_tiles_dataset = pd.DataFrame(usable_tiles_dataset, columns=['imgPath', 'maskPath']).sort_values('imgPath')\n",
    "    usable_tiles_dataset.to_csv(target_csv_dataset_path, index=False)\n",
    "    print(f\"Excluded {excluded_regions_num} regions for {target_csv_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684091146165,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "ca0I4XpDQwl6"
   },
   "outputs": [],
   "source": [
    "def create_one_channel_forest_dataset(horizontal_splits,\n",
    "                                      vertical_splits,\n",
    "                                      FINAL_DATASET_NAME,\n",
    "                                      img_file,\n",
    "                                      mask_file,\n",
    "                                      skip_img=False,\n",
    "                                      skip_mask=False):\n",
    "    # One Channel Dataset\n",
    "    satellite_img_path = os.path.join(dir_prefix, 'raw_forest', img_file)\n",
    "    nks_mask_path = os.path.join(dir_prefix, 'raw_forest', mask_file)\n",
    "    img_tiling_prefix = Path(satellite_img_path).stem + '_split_'\n",
    "    mask_tiling_prefix = Path(nks_mask_path).stem + '_split_'\n",
    "    target_imgtile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, Path(satellite_img_path).stem)\n",
    "    target_masktile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, Path(nks_mask_path).stem)\n",
    "    target_csv_dataset_path = os.path.join(dir_prefix,\n",
    "                                          FINAL_DATASET_NAME,\n",
    "                                          f\"Dataset-{Path(satellite_img_path).stem}-{Path(nks_mask_path).stem}.csv\")\n",
    "\n",
    "    os.makedirs(target_imgtile_path, exist_ok=True)\n",
    "    os.makedirs(target_masktile_path, exist_ok=True)\n",
    "\n",
    "    to_exclude_condition = lambda tiles_im, tiles_ma: ((tiles_ma < 0).sum()/tiles_ma.size > 0.5) or ((tiles_im == 0).sum()/tiles_im.size > 0.5) # Because mask has all class labels greater than 0 and everything else is -inf\n",
    "\n",
    "\n",
    "    image = cv2.imread(satellite_img_path, cv2.IMREAD_UNCHANGED)\n",
    "    mask = cv2.imread(nks_mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    image[image < 0] = 0\n",
    "    image[image > 255] = 255\n",
    "    image = np.uint8(image)\n",
    "\n",
    "    mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "    tile_image(\n",
    "        image=image,\n",
    "        mask=mask,\n",
    "        vertical_splits=vertical_splits,\n",
    "        horizontal_splits=horizontal_splits,\n",
    "        img_tiling_prefix=img_tiling_prefix,\n",
    "        mask_tiling_prefix=mask_tiling_prefix,\n",
    "        target_imgtile_path=target_imgtile_path,\n",
    "        target_masktile_path=target_masktile_path,\n",
    "        target_csv_dataset_path=target_csv_dataset_path,\n",
    "        to_exclude_condition=to_exclude_condition,\n",
    "        skip_img=skip_img,\n",
    "        skip_mask=skip_mask\n",
    "    )\n",
    "\n",
    "    del image\n",
    "\n",
    "    print(f\"num of files in {target_imgtile_path}: {len([name for name in os.listdir(target_imgtile_path) if os.path.join(target_imgtile_path, name)])}\")\n",
    "    print(f\"num of files in {target_masktile_path}: {len([name for name in os.listdir(target_masktile_path) if os.path.join(target_masktile_path, name)])}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 452070,
     "status": "ok",
     "timestamp": 1684092384909,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "KcTl0k0-RpZc",
    "outputId": "b3f73715-cd82-4818-ce8e-f5d01ef44db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_0-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_0: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_1-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_1: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_2-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_2: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_3-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_3: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_4-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_4: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_5-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_5: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_6-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_6: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 874 regions for /data/ForestDataset8C/Dataset-wv2_7-nks.csv\n",
      "num of files in /data/ForestDataset8C/wv2_7: 1600\n",
      "num of files in /data/ForestDataset8C/nks: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_0-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_0: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_1-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_1: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_2-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_2: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_3-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_3: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_4-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_4: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_5-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_5: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_6-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_6: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 872 regions for /data/ForestDataset8C/Dataset-wv2_7-nks_hrsume.csv\n",
      "num of files in /data/ForestDataset8C/wv2_7: 1600\n",
      "num of files in /data/ForestDataset8C/nks_hrsume: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_0-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_0: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_1-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_1: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_2-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_2: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_3-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_3: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_4-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_4: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_5-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_5: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_6-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_6: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n",
      "Excluded 1504 regions for /data/ForestDataset8C/Dataset-wv2_7-train_polygons.csv\n",
      "num of files in /data/ForestDataset8C/wv2_7: 1600\n",
      "num of files in /data/ForestDataset8C/train_polygons: 1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = ['wv2_0.tif', \n",
    "        'wv2_1.tif',\n",
    "        'wv2_2.tif',\n",
    "        'wv2_3.tif',\n",
    "        'wv2_4.tif',\n",
    "        'wv2_5.tif',\n",
    "        'wv2_6.tif',\n",
    "        'wv2_7.tif']\n",
    "\n",
    "for mask_name in ['nks.tif', 'nks_hrsume.tif', 'train_polygons.tif']:\n",
    "    for img_file in args:\n",
    "        create_one_channel_forest_dataset(horizontal_splits=40,\n",
    "                                          vertical_splits=40,\n",
    "                                          FINAL_DATASET_NAME='ForestDataset8C',\n",
    "                                          img_file=img_file,\n",
    "                                          mask_file=mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5670,
     "status": "ok",
     "timestamp": 1683491399124,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "UeAaJthvhUlE",
    "outputId": "2f3da273-da39-4b26-a3a9-4f87b42751fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/data/ForestDataset8C/wv2_4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFFUJ-P_wG4j"
   },
   "source": [
    "nks_old je stara verzija nks klasifikacije, Subasic je dobio access boljim kasifikacijama train polygons i nks_hrsume (msm da je to maska s semi automatskim labeliranjem podataka), i brojevi klasa su malo shiftani da se poklapaju s drugim maskama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6608,
     "status": "ok",
     "timestamp": 1683472233202,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "nUpXZqr5vmve",
    "outputId": "61879261-dbab-4f9d-dce3-384bbb5295cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nks_old shape: (851, 964)\n",
      "nks shape: (2605, 2814)\n",
      "nks_hrsume shape: (851, 964)\n",
      "train_polygons shape: (4170, 4626)\n",
      "nks_old freqs: (array([-3.4e+38,  1.0e+00,  2.0e+00,  3.0e+00,  4.0e+00,  5.0e+00,\n",
      "        6.0e+00,  7.0e+00,  8.0e+00,  9.0e+00,  1.0e+01,  1.1e+01,\n",
      "        1.2e+01,  1.3e+01,  1.4e+01], dtype=float32), array([440166,   1241,    322,   6264,   3904,  19341,   6936,   4348,\n",
      "        24765,  10283,  80180,  24209,  23012, 117578,  57815]))\n",
      "nks freqs: (array([-3.4e+38,  1.0e+00,  2.0e+00,  3.0e+00,  4.0e+00,  5.0e+00,\n",
      "        6.0e+00,  7.0e+00,  8.0e+00,  9.0e+00,  1.0e+01,  1.1e+01],\n",
      "      dtype=float32), array([3941754,  450152,  543822,   97827,  626456,   10203,   38057,\n",
      "        992117,   67195,  349082,  136990,   76815]))\n",
      "nks_hrsume freqs: (array([-3.4e+38,  1.0e+00,  2.0e+00,  3.0e+00,  4.0e+00,  5.0e+00,\n",
      "        6.0e+00,  7.0e+00,  8.0e+00,  1.0e+01,  1.1e+01,  1.2e+01],\n",
      "      dtype=float32), array([440141,  26149,  80413,  10232, 117493,  24246,  29920,  57872,\n",
      "         6291,   4405,   3898,  19304]))\n",
      "train_polygons freqs: (array([-3.4e+38,  1.0e+00,  2.0e+00,  3.0e+00,  4.0e+00,  5.0e+00,\n",
      "        6.0e+00,  7.0e+00,  8.0e+00,  9.0e+00,  1.0e+01,  1.1e+01,\n",
      "        1.2e+01], dtype=float32), array([18140621,   116160,   124198,    35507,   189895,    43751,\n",
      "          51364,   310660,    95878,    85028,    39871,    39511,\n",
      "          17976]))\n"
     ]
    }
   ],
   "source": [
    "nks_old = cv2.imread(os.path.join(dir_prefix, 'nks_old.tif'), cv2.IMREAD_UNCHANGED)\n",
    "nks = cv2.imread(os.path.join(dir_prefix, 'nks.tif'), cv2.IMREAD_UNCHANGED)\n",
    "nks_hrsume = cv2.imread(os.path.join(dir_prefix, 'nks_hrsume.tif'), cv2.IMREAD_UNCHANGED)\n",
    "train_polygons = cv2.imread(os.path.join(dir_prefix, 'train_polygons.tif'), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "print(f\"nks_old shape: {nks_old.shape}\")\n",
    "print(f\"nks shape: {nks.shape}\")\n",
    "print(f\"nks_hrsume shape: {nks_hrsume.shape}\")\n",
    "print(f\"train_polygons shape: {train_polygons.shape}\")\n",
    "print(f\"nks_old freqs: {np.unique(nks_old, return_counts=True)}\")\n",
    "print(f\"nks freqs: {np.unique(nks, return_counts=True)}\")\n",
    "print(f\"nks_hrsume freqs: {np.unique(nks_hrsume, return_counts=True)}\")\n",
    "print(f\"train_polygons freqs: {np.unique(train_polygons, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1683472284767,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "xYjUbaRxxAA2",
    "outputId": "30c79c8a-4f45-48cf-c626-dec4835f8fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827800829875518\n",
      "0.925728500355366\n"
     ]
    }
   ],
   "source": [
    "print(851/964)\n",
    "print(2605/2814)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asgRbD4326wJ"
   },
   "source": [
    "##  Forest Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29227,
     "status": "ok",
     "timestamp": 1680791216306,
     "user": {
      "displayName": "Ivan Klabučar",
      "userId": "04386316414841804865"
     },
     "user_tz": -120
    },
    "id": "GjjcsLOdVtoL",
    "outputId": "f88cf25e-49ff-4137-c775-9794c1128056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 873 regions\n"
     ]
    }
   ],
   "source": [
    "# One Channel Dataset\n",
    "\n",
    "horizontal_splits = 40\n",
    "vertical_splits = 40\n",
    "FINAL_DATASET_NAME = 'ForestDataset'\n",
    "satellite_img_path = os.path.join(dir_prefix, 'wv2_2.tif')\n",
    "nks_mask_path = os.path.join(dir_prefix, 'nks.tif')\n",
    "img_tiling_prefix = Path(satellite_img_path).stem + '_split_'\n",
    "mask_tiling_prefix = Path(nks_mask_path).stem + '_split_'\n",
    "target_imgtile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, Path(satellite_img_path).stem)\n",
    "target_masktile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, Path(nks_mask_path).stem)\n",
    "target_csv_dataset_path = os.path.join(dir_prefix,\n",
    "                                       FINAL_DATASET_NAME,\n",
    "                                       f\"Dataset-{Path(satellite_img_path).stem}-{Path(nks_mask_path).stem}.csv\")\n",
    "# os.mkdir(os.path.join(dir_prefix, FINAL_DATASET_NAME))\n",
    "# os.mkdir(target_imgtile_path)\n",
    "# os.mkdir(target_masktile_path)\n",
    "\n",
    "try:\n",
    "    os.makedirs(target_imgtile_path)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(target_masktile_path)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "to_exclude_condition = lambda tiles_im, tiles_ma: ((tiles_ma < 0).sum()/tiles_ma.size > 0.5) or ((tiles_im == 0).sum()/tiles_im.size > 0.5) # Because mask has all class labels greater than 0 and everything else is -inf\n",
    "\n",
    "\n",
    "image = cv2.imread(satellite_img_path, cv2.IMREAD_UNCHANGED)\n",
    "mask = cv2.imread(nks_mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "image[image < 0] = 0\n",
    "image[image > 255] = 255\n",
    "image = np.uint8(image)\n",
    "\n",
    "mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "tile_image(\n",
    "    image=image,\n",
    "    mask=mask,\n",
    "    vertical_splits=vertical_splits,\n",
    "    horizontal_splits=horizontal_splits,\n",
    "    img_tiling_prefix=img_tiling_prefix,\n",
    "    mask_tiling_prefix=mask_tiling_prefix,\n",
    "    target_imgtile_path=target_imgtile_path,\n",
    "    target_masktile_path=target_masktile_path,\n",
    "    target_csv_dataset_path=target_csv_dataset_path,\n",
    "    to_exclude_condition=to_exclude_condition,\n",
    "    skip_mask=True\n",
    ")\n",
    "\n",
    "del image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0bR73A83AQ4"
   },
   "source": [
    "## Three Channel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyef9xRjzQju"
   },
   "outputs": [],
   "source": [
    "# Three Channel Dataset\n",
    "\n",
    "horizontal_splits = 40\n",
    "vertical_splits = 40\n",
    "FINAL_DATASET_NAME = 'Three_Channel_ForestDataset'\n",
    "satellite_img_path_0 = os.path.join(dir_prefix, 'wv2_0.tif')\n",
    "satellite_img_path_1 = os.path.join(dir_prefix, 'wv2_1.tif')\n",
    "satellite_img_path_2 = os.path.join(dir_prefix, 'wv2_2.tif')\n",
    "nks_mask_path = os.path.join(dir_prefix, 'nks.tif')\n",
    "img_tiling_prefix = 'wv2_012' + '_split_'\n",
    "mask_tiling_prefix = Path(nks_mask_path).stem + '_split_'\n",
    "target_imgtile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, 'wv2_012')\n",
    "target_masktile_path = os.path.join(dir_prefix, FINAL_DATASET_NAME, Path(nks_mask_path).stem)\n",
    "os.mkdir(os.path.join(dir_prefix, FINAL_DATASET_NAME))\n",
    "os.mkdir(target_imgtile_path)\n",
    "os.mkdir(target_masktile_path)\n",
    "\n",
    "to_exclude_condition = lambda tiles_im, tiles_ma: ((tiles_ma < 0).sum()/tiles_ma.size > 0.5) or ((tiles_im == 0).sum()/tiles_im.size > 0.5) # Because mask has all class labels greater than 0 and everything else is -inf\n",
    "\n",
    "\n",
    "image_0 = cv2.imread(satellite_img_path_0, cv2.IMREAD_UNCHANGED)\n",
    "image_1 = cv2.imread(satellite_img_path_1, cv2.IMREAD_UNCHANGED)\n",
    "image_2 = cv2.imread(satellite_img_path_2, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "image = np.dstack([image_0,\n",
    "                   image_1,\n",
    "                   image_2])\n",
    "\n",
    "image[image < 0] = 0\n",
    "image[image > 255] = 255\n",
    "image = np.uint8(image)\n",
    "\n",
    "plt.imshow(image[3000:6000, 3000:6000, :])\n",
    "plt.title('image')\n",
    "plt.show()\n",
    "\n",
    "mask = cv2.imread(nks_mask_path, cv2.IMREAD_UNCHANGED)\n",
    "mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "tile_image(\n",
    "    image=image,\n",
    "    mask=mask,\n",
    "    vertical_splits=vertical_splits,\n",
    "    horizontal_splits=horizontal_splits,\n",
    "    img_tiling_prefix=img_tiling_prefix,\n",
    "    mask_tiling_prefix=mask_tiling_prefix,\n",
    "    target_imgtile_path=target_imgtile_path,\n",
    "    target_masktile_path=target_masktile_path,\n",
    "    to_exclude_condition=to_exclude_condition\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOdTYtJokzkkkfFbEcfspQv",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
